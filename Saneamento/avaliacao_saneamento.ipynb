{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e59c96",
   "metadata": {},
   "source": [
    "Esse arquivo tem como intuito tratar, 'plotar' e avaliar os datasets presentes a pasta Saneamento/datasets com o fim de compor a base metodológica do trabalho semestral de RP2 \"Uma análise quantitativa da distribuição de casos de dengue na cidade de São Paulo em suas várias granularidades.\"\n",
    "\n",
    "Para melhor aproveitamento desse arquivo use Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b377168",
   "metadata": {},
   "source": [
    "Logo abaixo, unimos os datasets (oriundos do IBGE) para facilitar a manipulação e tratamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d6418",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importar a biblioteca pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar os três datasets\n",
    "df1 = pd.read_csv('dataset1.csv')\n",
    "df2 = pd.read_csv('dataset2.csv')\n",
    "df3 = pd.read_csv('dataset3.csv')\n",
    "\n",
    "# Verificar as primeiras linhas para garantir que a coluna ID está correta\n",
    "print(\"Dataset 1:\")\n",
    "print(df1.head())\n",
    "print(\"\\nDataset 2:\")\n",
    "print(df2.head())\n",
    "print(\"\\nDataset 3:\")\n",
    "print(df3.head())\n",
    "\n",
    "# Supondo que a primeira coluna se chama 'ID' em todos os datasets\n",
    "# Unir df1 e df2 com base na coluna 'ID'\n",
    "merged_df = pd.merge(df1, df2, on='ID', how='inner')\n",
    "\n",
    "# Unir o resultado com df3\n",
    "final_df = pd.merge(merged_df, df3, on='ID', how='inner')\n",
    "\n",
    "# Verificar o dataset\n",
    "print(\"\\nDataset:\")\n",
    "print(final_df.head())\n",
    "\n",
    "# (Opcional) Salvar o dataset combinado\n",
    "final_df.to_csv('dataset_combinado.csv', index=False)\n",
    "# ================================\n",
    "# Eliminação de algumas variáveis: as que tratam do gênero dos ocupantes do domicílio, algo que não será investigado\n",
    "# Definindo os intervalos de início e fim\n",
    "intervalos = [\n",
    "    (0, 9),\n",
    "    (48, 54),\n",
    "    (112, 144),\n",
    "    (200, 203),\n",
    "    (310, 318),\n",
    "    (398, 404),\n",
    "    (464, 472),\n",
    "    (509, 517),\n",
    "    (541, 544),\n",
    "    (581, 589),\n",
    "    (613, 619),\n",
    "    (637, 641)\n",
    "]\n",
    "\n",
    "# gera a lista de índices de colunas a manter\n",
    "colunas_manter = [i for start, end in intervalos for i in range(start, end)]\n",
    "\n",
    "# seleciona apenas essas colunas (por posição)\n",
    "final_df = final_df.iloc[:, colunas_manter]\n",
    "\n",
    "# (Opcional) Salvar o dataset processado e verificar novamente as informações do dataset\n",
    "final_df.to_csv('dataset_combinado.csv', index=False)\n",
    "print(\"\\nInformações do dataset combinado:\")\n",
    "print(final_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc60ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b95759",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6213848",
   "metadata": {},
   "source": [
    "Aplicação das diretrizes de tratamento (remoção de nulos, inválidos, identificação de outliers, normalização e plotagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e3738",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#CODE FOR FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e1e3738",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Limpeza de Dados: Converter V00... columns para numérico, tratando 'X' como 0.\n",
    "# Identificar as colunas a serem processadas (todas as colunas, exceto 'ID')\n",
    "cols_to_convert = final_df.columns.drop('ID')\n",
    "\n",
    "# Substituição de 'X' (código de supressão) por 0 nas colunas de variáveis\n",
    "final_df[cols_to_convert] = final_df[cols_to_convert].replace('X', 0)\n",
    "\n",
    "# Conversão de todas as colunas de variáveis para o tipo numérico (inteiro)\n",
    "# O 'errors=\\'coerce\\'' garante que qualquer outro valor não numérico seja transformado em NaN,\n",
    "# que é subsequentemente preenchido com 0 por segurança.\n",
    "final_df[cols_to_convert] = final_df[cols_to_convert].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Extração do Código do Distrito (ID_Distrito)\n",
    "# O código do setor censitário (ID) tem 15 dígitos.\n",
    "# O código do Distrito (DD) corresponde aos dígitos na posição 8 e 9 (índice 7 e 8, começando em 0).\n",
    "final_df['ID_str'] = final_df['ID'].astype(str).str.zfill(15)\n",
    "final_df['ID_Distrito'] = final_df['ID_str'].str[7:9]\n",
    "\n",
    "# Agregação: Agrupar por ID_Distrito e somar as variáveis V00...\n",
    "# As variáveis de contagem do Censo devem ser somadas para agregar em um nível territorial maior.\n",
    "# Removemos as colunas 'ID_str' e 'ID' que não devem ser somadas.\n",
    "df_grouped = final_df.drop(columns=['ID_str', 'ID']).groupby('ID_Distrito').sum()\n",
    "\n",
    "# Resetar o índice para que 'ID_Distrito' volte a ser uma coluna de dados.\n",
    "df_grouped = df_grouped.reset_index()\n",
    "df_grouped['ID_Distrito'] = df_grouped['ID_Distrito'].astype(int)\n",
    "\n",
    "# Dataset com informações sobre os distritos - nome, área\n",
    "df_nomes_distritos = pd.read_csv('Documents/codigos_distritos_msp.csv', sep=';')\n",
    "\n",
    "# Juntar os dois DataFrames pela coluna ID_Distrito\n",
    "df_final = pd.merge(\n",
    "    df_grouped,\n",
    "    df_nomes_distritos,\n",
    "    on='ID_Distrito',\n",
    "    how='left'  # Usa 'left' para manter todos os distritos do seu dataset de saneamento.\n",
    ")\n",
    "colunas_principais = ['ID_Distrito', 'Nome']\n",
    "\n",
    "## Obter todas as outras colunas (removendo as colunas duplicadas do merge e as principais)\n",
    "colunas_restantes = [\n",
    "    col for col in df_final.columns\n",
    "    if col not in colunas_principais and not col.endswith('_x') and not col.endswith('_y')\n",
    "]\n",
    "\n",
    "## Criar a nova ordem da coluna\n",
    "nova_ordem_colunas = colunas_principais + colunas_restantes\n",
    "\n",
    "## Aplicar a nova ordem ao DataFrame\n",
    "df_final = df_final[nova_ordem_colunas]\n",
    "\n",
    "# Salvar o arquivo resultante\n",
    "df_final.to_csv('dataset_agrupado_por_distrito.csv', index=False)\n",
    "print(\"\\nInformações do dataset final:\")\n",
    "print(df_final.info())\n",
    "\n",
    "# Exibir informações de confirmação\n",
    "print(\"Dados Agrupados por Distrito (Primeiras Linhas):\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d0218",
   "metadata": {},
   "source": [
    "Avaliação"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
