{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e59c96",
   "metadata": {},
   "source": [
    "Esse arquivo tem como intuito tratar, 'plotar' e avaliar os datasets presentes a pasta Saneamento/datasets com o fim de compor a base metodológica do trabalho semestral de RP2 \"Uma análise quantitativa da distribuição de casos de dengue na cidade de São Paulo em suas várias granularidades.\"\n",
    "\n",
    "Para melhor aproveitamento desse arquivo use Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d6418",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importar a biblioteca pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar os três datasets\n",
    "df1 = pd.read_csv('dataset1.csv')\n",
    "df2 = pd.read_csv('dataset2.csv')\n",
    "df3 = pd.read_csv('dataset3.csv')\n",
    "\n",
    "# Verificar as primeiras linhas para garantir que a coluna ID está correta\n",
    "print(\"Dataset 1:\")\n",
    "print(df1.head())\n",
    "print(\"\\nDataset 2:\")\n",
    "print(df2.head())\n",
    "print(\"\\nDataset 3:\")\n",
    "print(df3.head())\n",
    "\n",
    "# Supondo que a primeira coluna se chama 'ID' em todos os datasets\n",
    "# Unir df1 e df2 com base na coluna 'ID'\n",
    "merged_df = pd.merge(df1, df2, on='ID', how='inner')\n",
    "\n",
    "# Unir o resultado com df3\n",
    "final_df = pd.merge(merged_df, df3, on='ID', how='inner')\n",
    "\n",
    "# Verificar o dataset final\n",
    "print(\"\\nDataset final:\")\n",
    "print(final_df.head())\n",
    "print(\"\\nInformações do dataset final:\")\n",
    "print(final_df.info())\n",
    "\n",
    "# (Opcional) Salvar o dataset combinado\n",
    "final_df.to_csv('dataset_combinado.csv', index=False)"

    ## Eliminacao de algumas variaveis: as que tratam do gênero dos ocupantes do domicílio, algo que não será investigado
    # Definindo os intervalos de início e fim
    intervalos = [
        (11, 17),
        (72, 74),
        (105, 111),
        (183, 199),
        (226, 232),
        (295, 309),
        (381, 397),
        (451, 463),
        (481, 485),
        (502, 508),
        (524, 540),
        (546, 552),
        (566, 580),
        (596, 612),
        (624, 636),
        (640, 644),
    ]
    
    # Gerar todos os nomes de colunas
    cols_to_drop = [ f'V{i:05d}' for (start, end) in intervalos for i in range(start, end) ]
    
    # Dropar as colunas
    final_df = final_df.drop(columns=cols_to_drop)
    final_df.to_csv('dataset_combinado.csv', index=False)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b95759",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
